=== MODEL SETUP ===

preprocessing: True
classification: ternary
Twitter embeddings: True
Train set size: 17343
Test set size: 12284
Vocabulary size: 14853
earlystop | monitor: loss, min_delta: -0.01, patience: 2
epochs: 10
batch_size: 32
dropout: 0.5
extra train (ynacc): False
====================

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 124)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 124, 300)          4455900   
_________________________________________________________________
dropout_1 (Dropout)          (None, 124, 300)          0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 124, 300)          721200    
_________________________________________________________________
lstm_2 (LSTM)                (None, 124, 300)          721200    
_________________________________________________________________
lstm_3 (LSTM)                (None, 300)               721200    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 303       
=================================================================
Total params: 6,649,903
Trainable params: 2,194,003
Non-trainable params: 4,455,900
_________________________________________________________________
              precision    recall  f1-score   support

    negative      0.392     0.882     0.543      3972
     neutral      0.612     0.258     0.363      5937
    positive      0.661     0.236     0.348      2375

   micro avg      0.455     0.455     0.455     12284
   macro avg      0.555     0.459     0.418     12284
weighted avg      0.551     0.455     0.418     12284

[[3504  427   41]
 [4161 1530  246]
 [1274  541  560]]
