=== MODEL SETUP ===

preprocessing: True
classification: ternary
Twitter embeddings: True
Train set size: 50334
Test set size: 12284
Vocabulary size: 44350
earlystop | monitor: loss, min_delta: -0.01, patience: 2
epochs: 10
batch_size: 32
dropout: 0.5
extra train (ynacc): True
====================

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 124)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 124, 300)          13305000  
_________________________________________________________________
dropout_1 (Dropout)          (None, 124, 300)          0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 124, 300)          721200    
_________________________________________________________________
lstm_2 (LSTM)                (None, 124, 300)          721200    
_________________________________________________________________
lstm_3 (LSTM)                (None, 300)               721200    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 303       
=================================================================
Total params: 15,499,003
Trainable params: 2,194,003
Non-trainable params: 13,305,000
_________________________________________________________________
              precision    recall  f1-score   support

    negative      0.342     0.638     0.445      3972
     neutral      0.511     0.378     0.434      5937
    positive      0.429     0.087     0.145      2375

   micro avg      0.406     0.406     0.406     12284
   macro avg      0.427     0.368     0.341     12284
weighted avg      0.441     0.406     0.382     12284

[[2534 1334  104]
 [3523 2243  171]
 [1356  812  207]]
