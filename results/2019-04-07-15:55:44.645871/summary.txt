=== MODEL SETUP ===

preprocessing: True
classification: ternary
Twitter embeddings: True
Train set size: 50334
Test set size: 12284
Vocabulary size: 39905
earlystop | monitor: loss, min_delta: -0.01, patience: 2
epochs: 10
batch_size: 32
dropout: 0.5
extra train (ynacc): False
====================

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 67)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 67, 300)           11971500  
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 300)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 67, 300)           721200    
_________________________________________________________________
lstm_2 (LSTM)                (None, 300)               721200    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 303       
=================================================================
Total params: 13,444,303
Trainable params: 1,472,803
Non-trainable params: 11,971,500
_________________________________________________________________
              precision    recall  f1-score   support

    negative      0.775     0.422     0.547      3972
     neutral      0.621     0.756     0.682      5937
    positive      0.562     0.683     0.617      2375

   micro avg      0.634     0.634     0.634     12284
   macro avg      0.653     0.621     0.615     12284
weighted avg      0.659     0.634     0.626     12284

[[1677 2025  270]
 [ 453 4490  994]
 [  34  718 1623]]
