=== MODEL SETUP ===

preprocessing: True
classification: ternary
Twitter embeddings: True
Train set size: 50334
Test set size: 12284
Vocabulary size: 39905
earlystop | monitor: loss, min_delta: -0.01, patience: 2
epochs: 10
batch_size: 32
dropout: 0.5
====================

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 67)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 67, 300)           11971500  
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 300)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 67, 300)           721200    
_________________________________________________________________
lstm_2 (LSTM)                (None, 300)               721200    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 303       
=================================================================
Total params: 13,444,303
Trainable params: 1,472,803
Non-trainable params: 11,971,500
_________________________________________________________________
              precision    recall  f1-score   support

    negative      0.659     0.665     0.662      3972
     neutral      0.691     0.599     0.642      5937
    positive      0.548     0.721     0.623      2375

   micro avg      0.644     0.644     0.644     12284
   macro avg      0.633     0.662     0.642     12284
weighted avg      0.653     0.644     0.645     12284

[[2641 1039  292]
 [1261 3558 1118]
 [ 108  555 1712]]
